name: Reusable - Deploy Terraform

on:
  workflow_call:
    inputs:
      action:
        required: false
        type: string
        default: 'apply'
      workdir:
        required: true
        type: string
      service-path:
        required: true
        type: string
      environment:
        required: true
        type: string
      stack:
        required: true
        type: string
    secrets:
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true

jobs:
  terraform:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write # Required for OIDC authentication with AWS

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-west-3 # Should match your common.tfvars

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Download and Unpack Deployment Package
        if: inputs.action == 'apply' && inputs.environment != 'global'
        run: |
          # Define package names for both the specific stack (e.g., pr123) and the fallback (rc)
          # The service name is derived from the service-path input
          SERVICE_NAME=$(basename "${{ inputs.service-path }}")
          STACK_PACKAGE_NAME="${SERVICE_NAME}-package.zip" # This is the name inside the S3 key
          RC_PACKAGE_NAME="${SERVICE_NAME}-package.zip"

          S3_BUCKET="sally-package-registry"
          # Construct the S3 key using the stack name (e.g., pr123, staging)
          STACK_S3_KEY="packages/${SERVICE_NAME}-${{ inputs.stack }}.zip"
          RC_S3_KEY="packages/${SERVICE_NAME}-rc.zip"

          echo "Attempting to download package: ${STACK_S3_KEY}"
          # Try to download the stack-specific package. If it fails (||), try to download the rc package.
          # The `aws s3 cp` command will exit with a non-zero status if the file is not found.
          (aws s3 cp "s3://${S3_BUCKET}/${STACK_S3_KEY}" "${STACK_PACKAGE_NAME}" && echo "Downloaded ${STACK_PACKAGE_NAME}") || \
          (aws s3 cp "s3://${S3_BUCKET}/${RC_S3_KEY}" "${RC_PACKAGE_NAME}" && echo "Downloaded fallback ${RC_PACKAGE_NAME}")

          # Unzip whichever package was successfully downloaded
          PACKAGE_TO_UNZIP=$(ls *-package.zip | head -n 1)
          echo "Unpacking artifact: ${PACKAGE_TO_UNZIP}"
          unzip -o "${PACKAGE_TO_UNZIP}" -d .
          # The package contains a 'terraform' directory, so we can now work with it.

      - name: Run Database Migrations via Lambda (if applicable)
        if: inputs.action == 'apply' && inputs.environment != 'global' && hashFiles('alembic.ini') != ''
        run: |
          echo "--- Found alembic.ini, invoking migration runner Lambda... ---"
          S3_KEY="packages/$(basename "${{ inputs.service-path }}")-${{ inputs.stack }}.zip"
          FUNCTION_NAME="sally-${{ inputs.stack }}-migration-runner"

          PAYLOAD=$(jq -n --arg key "$S3_KEY" '{s3_key: $key}')

          aws lambda invoke \
            --invocation-type RequestResponse \
            --function-name "$FUNCTION_NAME" \
            --payload "$PAYLOAD" \
            --cli-binary-format raw-in-base64-out \
            --log-type Tail \
            output.json
          
          # Check the output of the Lambda function
          STATUS=$(jq -r '.status' output.json)
          
          if [ "$STATUS" != "SUCCESS" ]; then
            echo "::error::Lambda migration failed!"
            jq '.' output.json # Print the full error output
            exit 1
          fi
          echo "Lambda migration successful."

      - name: Terraform Init
        run: |
          terraform init \
            -backend-config="bucket=sally-terraform-state-bucket" \
            -backend-config="key=${{ inputs.stack }}/${{ inputs.service-path }}/terraform.tfstate" \
            -backend-config="region=eu-west-3"
        working-directory: ./${{ inputs.workdir }}/terraform

      - name: Terraform Plan
        if: false
        run: |
          TF_VARS=""
          if [ "${{ inputs.environment }}" != "global" ]; then
            cp "../environments/common.tfvars" .
            cp "../environments/${{ inputs.environment }}.tfvars" .
            TF_VARS="-var-file=common.tfvars -var-file=${{ inputs.environment }}.tfvars"
          fi
          terraform plan -no-color -var="stack=${{ inputs.stack }}" ${TF_VARS}
        working-directory: ./${{ inputs.workdir }}/terraform

      - name: Terraform Apply
        if: inputs.action == 'apply' && (github.ref == 'refs/heads/main' || github.event_name == 'pull_request')
        run: |
          TF_VARS=""
          if [ "${{ inputs.environment }}" != "global" ]; then
            cp "../environments/common.tfvars" .
            cp "../environments/${{ inputs.environment }}.tfvars" .
            TF_VARS="-var-file=common.tfvars -var-file=${{ inputs.environment }}.tfvars"
          fi
          terraform apply -auto-approve -no-color -var="stack=${{ inputs.stack }}" ${TF_VARS}
        working-directory: ./${{ inputs.workdir }}/terraform

      - name: Terraform Destroy
        if: inputs.action == 'destroy'
        run: |
          TF_VARS=""
          if [ "${{ inputs.environment }}" != "global" ]; then
            cp "../environments/common.tfvars" .
            cp "../environments/${{ inputs.environment }}.tfvars" .
            TF_VARS="-var-file=common.tfvars -var-file=${{ inputs.environment }}.tfvars"
          fi
          terraform destroy -auto-approve -no-color -var="stack=${{ inputs.stack }}" ${TF_VARS}
        working-directory: ./${{ inputs.workdir }}/terraform
